{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Logisticregressionfromscratch.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {},
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import pandas as pd  \n",
        "import numpy as np  "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {},
      "outputs": [],
      "source": [
        "import matplotlib.pyplot as plt  \n",
        "import seaborn as seabornInstance \n",
        "from sklearn.model_selection import train_test_split \n",
        "from sklearn.linear_model import LinearRegression\n",
        "from sklearn import metrics"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {},
      "outputs": [],
      "source": [
        "data = pd.read_csv('logreg_ds.txt', sep=\",\", header=None) #Loading of datasheet"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>0</th>\n      <th>1</th>\n      <th>2</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>34.623660</td>\n      <td>78.024693</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>30.286711</td>\n      <td>43.894998</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>35.847409</td>\n      <td>72.902198</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>60.182599</td>\n      <td>86.308552</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>79.032736</td>\n      <td>75.344376</td>\n      <td>1</td>\n    </tr>\n  </tbody>\n</table>\n</div>",
            "text/plain": "           0          1  2\n0  34.623660  78.024693  0\n1  30.286711  43.894998  0\n2  35.847409  72.902198  0\n3  60.182599  86.308552  1\n4  79.032736  75.344376  1"
          },
          "execution_count": 8,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "data.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {},
      "outputs": [],
      "source": [
        "data.columns = [\"EXAM 1 SCORE\",\"EXAM 2 SCORE\", \"Y\"] #Adding header to columns\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {},
      "outputs": [],
      "source": [
        "x=data[['EXAM 1 SCORE','EXAM 2 SCORE']]\n",
        "y=data['Y']\n",
        "m=len(y)\n",
        "X=x.values\n",
        "Y=y.values"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {},
      "outputs": [],
      "source": [
        "from sklearn import preprocessing \n",
        "min_max_scaler = preprocessing.MinMaxScaler(feature_range =(0, 1)) \n",
        "  \n",
        "# Scaled feature \n",
        "X = min_max_scaler.fit_transform(X) "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": "array([[-1.60224763,  0.63834112],\n       [-1.82625564, -1.2075414 ],\n       [-1.53903969,  0.3612943 ],\n       [-0.28210129,  1.0863683 ],\n       [ 0.69152826,  0.49337794],\n       [-1.06199728, -0.5357394 ],\n       [-0.23437234,  1.63818413],\n       [ 0.4845113 , -1.06373024],\n       [ 0.53998666,  1.14651105],\n       [ 0.97044832, -1.22709853],\n       [ 1.56075461, -1.51418452],\n       [ 0.48393864, -1.92641626],\n       [ 0.86065022,  0.55490359],\n       [ 0.1921582 ,  1.70347834],\n       [-1.34839922,  0.53082781],\n       [-0.60293429,  1.24314792],\n       [ 0.17694982, -0.72913975],\n       [ 0.11893077, -1.05699346],\n       [ 0.25914553,  1.44433023],\n       [ 0.58543944, -1.00845873],\n       [ 0.0892403 , -1.26468472],\n       [ 1.2413042 , -0.02285779],\n       [-0.78042096, -0.93923898],\n       [-1.62350714, -1.19053019],\n       [ 0.63426559,  0.14875155],\n       [-0.17423248,  0.20186768],\n       [ 0.75131151, -1.15742514],\n       [ 1.41886056, -1.4830648 ],\n       [-0.19700066, -0.86350486],\n       [-1.38726847, -0.06632457],\n       [-0.22029098,  0.35619356],\n       [ 1.02063763, -0.49595429],\n       [-0.69916396, -0.16735724],\n       [-0.70239602,  0.1736574 ],\n       [-1.31231814,  0.26748769],\n       [-0.56863523, -0.7576197 ],\n       [-1.63882482,  1.76571557],\n       [-0.07578684,  0.7942862 ],\n       [ 0.47234786, -1.33310268],\n       [-1.62497511,  0.48760951],\n       [ 0.94305124, -0.53618968],\n       [-0.72810195, -1.0473818 ],\n       [ 1.48750373, -0.03532122],\n       [ 0.86383711, -1.38476189],\n       [-0.75392586, -1.10328278],\n       [-0.17672918, -0.76588887],\n       [ 0.59650575,  0.22911224],\n       [ 1.65941042,  1.10904426],\n       [-0.1844568 ,  1.65210535],\n       [ 1.33883167,  1.2155077 ],\n       [ 0.73863826,  0.42949041],\n       [ 1.73693492, -0.2824808 ],\n       [ 1.28623744, -1.23482132],\n       [-1.60736862, -0.31507682],\n       [-0.79324552, -0.88792768],\n       [-0.82939191, -0.34684551],\n       [ 1.65290418,  0.14275969],\n       [-1.70794943,  1.5888117 ],\n       [ 0.44442728,  0.19484284],\n       [ 0.31776703,  0.66153625],\n       [ 0.50366692,  1.05669679],\n       [-1.56803122, -1.03849986],\n       [-0.48502704, -1.45814261],\n       [-1.83802631, -0.89937003],\n       [-1.08343328,  0.012336  ],\n       [ 0.04734442, -1.35913441],\n       [-1.30092096,  1.69355351],\n       [-0.85594644, -0.77550399],\n       [ 0.75592876,  1.40046365],\n       [ 0.05694243, -0.28289384],\n       [-1.70042734, -1.23933351],\n       [-0.08289756,  0.63871945],\n       [ 0.34617678,  1.62283321],\n       [-0.26788246,  0.37172177],\n       [-0.35139858,  0.52118118],\n       [ 1.76561835,  0.33247025],\n       [-0.94934675,  1.20358601],\n       [-0.78437891,  0.51855329],\n       [-0.26800277, -1.28253412],\n       [ 0.8564979 , -1.27109695],\n       [ 1.20190067,  0.19371884],\n       [ 1.50770647, -1.11022692],\n       [ 0.08651467,  0.01986816],\n       [-0.43415649, -0.36278249],\n       [ 0.76043181,  1.33794685],\n       [ 0.14587539,  1.04773882],\n       [-1.21735452,  0.68269533],\n       [ 0.50790698,  1.30897879],\n       [ 0.67100669,  1.64553968],\n       [-0.68676645, -0.29489455],\n       [ 1.46947562,  0.59152637],\n       [ 1.28116721,  1.15128248],\n       [-0.52488391, -1.65775547],\n       [ 0.45703019,  1.00722043],\n       [ 1.25003483, -1.12840052],\n       [ 0.92170742, -0.96495748],\n       [-1.2077347 ,  1.12938152],\n       [ 1.73912916,  0.13809961],\n       [-0.53222578, -0.06977207],\n       [ 0.4716578 ,  1.26058811]])"
          },
          "execution_count": 12,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "Standardisation = preprocessing.StandardScaler() \n",
        "  \n",
        "# Scaled feature \n",
        "X = Standardisation.fit_transform(X)\n",
        "X "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {},
      "outputs": [],
      "source": [
        "b = np.ones((100,1))\n",
        "X = np.column_stack((b, X))  #Adding a bias value of 1 after standardising the other two columns in the training set"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {},
      "outputs": [],
      "source": [
        "theta0=0;\n",
        "theta1=0;\n",
        "theta2=0;\n",
        "theta=[[theta0],[theta1],[theta2]]; #Intialising theta to be 3*1 vector and initial values to be zero."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": "array([[0],\n       [0],\n       [0],\n       [1],\n       [1],\n       [0],\n       [1],\n       [1],\n       [1],\n       [1],\n       [0],\n       [0],\n       [1],\n       [1],\n       [0],\n       [1],\n       [1],\n       [0],\n       [1],\n       [1],\n       [0],\n       [1],\n       [0],\n       [0],\n       [1],\n       [1],\n       [1],\n       [0],\n       [0],\n       [0],\n       [1],\n       [1],\n       [0],\n       [1],\n       [0],\n       [0],\n       [0],\n       [1],\n       [0],\n       [0],\n       [1],\n       [0],\n       [1],\n       [0],\n       [0],\n       [0],\n       [1],\n       [1],\n       [1],\n       [1],\n       [1],\n       [1],\n       [1],\n       [0],\n       [0],\n       [0],\n       [1],\n       [0],\n       [1],\n       [1],\n       [1],\n       [0],\n       [0],\n       [0],\n       [0],\n       [0],\n       [1],\n       [0],\n       [1],\n       [1],\n       [0],\n       [1],\n       [1],\n       [1],\n       [1],\n       [1],\n       [1],\n       [1],\n       [0],\n       [0],\n       [1],\n       [1],\n       [1],\n       [1],\n       [1],\n       [1],\n       [0],\n       [1],\n       [1],\n       [0],\n       [1],\n       [1],\n       [0],\n       [1],\n       [1],\n       [1],\n       [1],\n       [1],\n       [1],\n       [1]])"
          },
          "execution_count": 15,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "Y=Y.reshape(100,1) #Reshaping the test data\n",
        "Y"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {},
      "outputs": [],
      "source": [
        "def sigmoid(z):   #Defining the sigmoid function for logistic regression\n",
        "    return 1 / (1 + np.exp(-z))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {},
      "outputs": [],
      "source": [
        "def cost(theta, X, Y):    #Defining the cost function\n",
        "    \n",
        "    first = np.multiply(-Y, np.log(sigmoid(np.dot(X,theta))))\n",
        "    second = np.multiply((1 - Y), np.log(1 - sigmoid(np.dot(X,theta))))\n",
        "    return np.sum(first - second) / (len(X))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": "0.6931471805599453"
          },
          "execution_count": 18,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "cost(theta,X,Y)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "metadata": {},
      "outputs": [],
      "source": [
        "for i in range(500):   #Performing gradient descent, running the loop for 400 times, setting the learning parameter alpha to be 1.\n",
        "    t=np.subtract(sigmoid(np.dot(X,theta)),Y)\n",
        "    grad0=(1/100)*(np.sum(t))\n",
        "    grad1=(1/100)*(np.sum(np.multiply(t,X[:,1].reshape(100,1))))\n",
        "    grad2=(1/100)*(np.sum(np.multiply(t,X[:,2].reshape(100,1))))\n",
        "    temp0=theta0- (1/100)*(np.sum(t))\n",
        "    temp1=theta1-(1/100)*(np.sum(np.multiply(t,X[:,1].reshape(100,1))))\n",
        "    temp2=theta2-(1/100)*(np.sum(np.multiply(t,X[:,2].reshape(100,1))))\n",
        "    theta0=temp0\n",
        "    theta1=temp1\n",
        "    theta2=temp2\n",
        "    theta=[[theta0],[theta1],[theta2]]\n",
        "  \n",
        "   \n",
        "\n",
        "  "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": "0.20352792136700593"
          },
          "execution_count": 20,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "cost(theta,X,Y)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 21,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": "accuracy = 89%\n"
        }
      ],
      "source": [
        "def predict(theta, X):       #Checking the accuracy \n",
        "    probability = sigmoid(np.dot(X,theta))\n",
        "    return [1 if x >= 0.5 else 0 for x in probability]\n",
        "\n",
        "theta_min = theta\n",
        "predictions = predict(theta_min, X)\n",
        "correct = [1 if ((a == 1 and b == 1) or (a == 0 and b == 0)) else 0 for (a, b) in zip(predictions, y)]\n",
        "accuracy = (sum(correct) % len(correct))\n",
        "print ('accuracy = {0}%'.format(accuracy))"
      ]
    }
  ]
}